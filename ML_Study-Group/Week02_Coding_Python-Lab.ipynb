{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 02 Coding: Numpy, Pandas, and MatPlotLib (Lab)\n",
    "\n",
    "## BEENOS Inc. Machine Learning Study Group\n",
    "\n",
    "In the second week, you'll practice using `numpy`, `pandas` and `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2 to every element of a `list`\n",
    "\n",
    "mylist = [1, 2, 3, 4, 5]\n",
    "\n",
    "mylist + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But such an operation is trivial for `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 2 to every element of an `ndarray`\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "myarray = np.array([1,2,3,4,5])\n",
    "\n",
    "myarray + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `numpy` to create matrices from lists of lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 3x3 matrix from a list of list\n",
    "\n",
    "morelists = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "mymatrix = np.array(morelists)\n",
    "\n",
    "mymatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy` Practice\n",
    "\n",
    "For the first part of this lab, you'll be completing short exercises to get you used to working with `numpy` arrays.\n",
    "\n",
    "The exercises are taken from [Machine Learning Plus](https://www.machinelearningplus.com/python/101-numpy-exercises-python/) and increase in difficulty from Level 1 to Level 4.\n",
    "\n",
    "Feel free to skip around to exercises that challenge you.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.0** Import numpy as `np` and print the version.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `1.15.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.1** Use `np.array` to create a 1D array of numbers from 0 to 9.\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.2** Extract all odd numbers from `arr`.\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> array([1, 3, 5, 7, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.3** Use `reshape` to convert a 1D array to a 2D array with two rows.\n",
    "\n",
    "*Output:*\n",
    "\n",
    ">     array([[0, 1, 2, 3, 4],\n",
    ">            [5, 6, 7, 8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.4** Use `np.full` to create an nD boolean array. Choose your size and `True` or `False`.\n",
    "\n",
    "*Sample Output:*\n",
    "\n",
    ">     array([[ True,  True],\n",
    ">            [ True,  True],\n",
    ">            [ True,  True]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.5** Use `np.where` to replace all odd numbers in `arr` with `-1`, but **DO NOT** change `arr`.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> array([ 0, -1,  2, -1,  4, -1,  6, -1,  8, -1]) `# newarray`\n",
    "\n",
    "> array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) `# arr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.arange(10)\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n",
    "print(arr, newarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.6** Create the following pattern. **Use numpy functions.**\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> array([1, 1, 1, 2, 2, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3])\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.7** Get all common items in both `a` and `b`.\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> array([2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,2,3,4,3,4,5,6])\n",
    "b = np.array([7,2,10,2,7,4,9,4,9,8])\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.8** Remove from `a` all items in `b`.\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> array([0, 1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,2,3,4,5])\n",
    "b = np.array([3,5,6,7,8,9])\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.9** Create a 2D array of size 5x3 containing random numbers between 5 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.10** Use `np.genfromtxt` to import the Iris flowers dataset from the given url.\n",
    "\n",
    "*Hint: If your last column shows `nan` values, trying specifying an `object` data type.*\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> `# Print the first row`\n",
    "\n",
    "> array([[b'5.1', b'3.5', b'1.4', b'0.2', b'Iris-setosa']], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pandas\n",
    "\n",
    "[CHANGE TO PANDAS]\n",
    "NumPy is short for Numerical Python, and it is the most important package one needs when working with data in Python.\n",
    "\n",
    "Other popular packages, like `pandas`, depend on the versatile functionality provided by numpy.\n",
    "\n",
    "The core benefit to using `numpy` is access to its `ndarray` objects.\n",
    "\n",
    "`ndarray` is short for **n-dimensional arrays**, which allow us to perform vectorized mathematical operations and data manipulation on collections of data.\n",
    "\n",
    "### `pandas` Practice\n",
    "\n",
    "For the next part of this lab, you'll be completing short exercises to get you used to working with `numpy` arrays.\n",
    "\n",
    "The exercises are taken from [Machine Learning Plus](https://www.machinelearningplus.com/python/101-pandas-exercises-python/) and increase in difficulty from Level 1 to Level 3.\n",
    "\n",
    "Feel free to skip around to exercises that challenge you.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.0** Pandas relies on `numpy`. You should have already imported `numpy`. If not, import it and also import pandas (by convention as `pd`) and check your `pandas` version.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `0.23.4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.1** Like `numpy`, `pandas` has popular structures that it is well known for. The first one is called a **Series**, which is a one-dimensional array. In laymans terms, a Series is simply a *column* of data, like one might find in an Excel spreadsheet.\n",
    "\n",
    "A Series can hold any data type and can be coerced from multiple data structures. To test this, convert each of the following data structures (a list, an array and a dictionary) into a separate **Series**.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `# Print the head of the mydict series`\n",
    "\n",
    ">     a     0\n",
    ">     b     1\n",
    ">     c     2\n",
    ">     d     3\n",
    ">     e     4\n",
    ">     dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list('abcdefghijklmnopqrstuvwyxz')\n",
    "myarray = np.arange(1, 27)\n",
    "mydict = dict(zip(mylist,myarray))\n",
    "\n",
    "mylist_to_series =  # INSERT CODE HERE\n",
    "myarray_to_series = # INSERT CODE HERE\n",
    "mydict_to_series =  # INSERT CODE HERE\n",
    "\n",
    "mydict_to_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.2** Series can also be coerced into the second fundamental `pandas` data structure, the **DataFrame**. It is a two-dimensional array made up of Series. Again, in laymans terms, a DataFrame is like one spreadsheet in Excel: it contains multiple columns.\n",
    "\n",
    "Each column of a DataFrame cna hold any data type, and can be created from Series or other data structures. Let's try this by turning your `mydict` series into a `pandas` DataFrame. Use `.reset_index()` to add *both* columns to the table.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `# Print the head of the dataframe`\n",
    "\n",
    ">           index  0\n",
    ">     0     a      0\n",
    ">     1     b      1\n",
    ">     2     c      2\n",
    ">     3     d      3\n",
    ">     4     e      4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseries = pd.Series(mydict)\n",
    "\n",
    "mydataframe = # INSERT CODE HERE\n",
    "\n",
    "mydataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.3** Our new dataframe looks a bit clunky. One problem is the column names `\"index\"` and `\"0\"` don't tell us much about the data in the table.\n",
    "\n",
    "It might be easier to read if we change those names to `\"letter\"` and `\"position\"`, or even `\"number\"`. You can use `.rename()`.\n",
    "\n",
    "*Hint: Does your head show `'index'` and `'0'` still? Try using `inplace`!*\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `# Print the head of the dataframe`\n",
    "\n",
    ">           letter  number\n",
    ">     0     a       1\n",
    ">     1     b       2\n",
    ">     2     c       3\n",
    ">     3     d       4\n",
    ">     4     e       5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT CODE HERE\n",
    "\n",
    "mydataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.4** Alright, let's practice with a bit of real data. We'll be looking at the [Cars93](https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv) dataset for a few problems.\n",
    "\n",
    "The dataset has already been loaded for you. Figure out how many rows and columns it contains.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> (93, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv\")\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.5** Let's get a bit more info on our dataset. First, we want to figure out the *type* of the data that exists within each column. (What are we working with? Strings? Integers? Floats? Datetime objects?)\n",
    "\n",
    "This is extremely important to know for manipulating our dataset later, because **all the data in a pandas *Series* or a DataFrame *column* must be the same**.\n",
    "\n",
    "What types are in the Cars93 dataset?\n",
    "\n",
    "*Sample Output (first 3 data types)*:\n",
    "\n",
    ">     Manufacturer    object\n",
    ">     Model           object\n",
    ">     Type            object\n",
    ">     dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.6** As you work with real data, you'll soon find out that the more you *know* about the dataset you're working with, the easier it is to build models and make predictions.\n",
    "\n",
    "One of the things you'll want to know is **summary statistics**: things like mean, standard deviation, maximum and minimum values, etc. Knowing these stats will help you determine whether your data needs to undergo transformation (like scaling and normalization) before modeling.\n",
    "\n",
    "Show the summary stats for this dataset now. What is each row telling you?\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    "> `# First few columns of the first rows`\n",
    "\n",
    ">               Min.Price       Price           Max.Price\n",
    ">     count     86.000000       91.000000       88.000000       ...\n",
    ">     mean      17.118605       19.616484       21.459091       ...\n",
    ">     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.7** Let's use our summary statistics to learn more about our data.\n",
    "\n",
    "Find the `manufacturer`, `model` and `type` of car that has the highest `Price`. Use `.loc[]` to pull out this information.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    ">               Manufacturer    Model     Type       Price\n",
    ">     58        Mercedes-Benz   300E      Midsize    61.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.8** We want to see if our dataset has any missing values. (If it does, we may need to transform them to make the dataset compatible with machine learning algorithms.)\n",
    "\n",
    "Find all the missing values in the dataset now.\n",
    "\n",
    "*Sample Output*:\n",
    "\n",
    ">               Manufacturer    Model     Type       Price\n",
    ">     58        Mercedes-Benz   300E      Midsize    61.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.9** Normally, we'd need to take a closer look at each column containing `null` values before deciding what to do with them. But for the purpose of this notebook, let's just assume we want to get rid of them!\n",
    "\n",
    "If you ran the above cell correctly, it should show that the `'Model'` column only has one missing value. We shouldn't miss this one too much. **Drop this row now.** Then, check to see how many missing values are in that column.\n",
    "\n",
    "*Hint: If your code still shows 1 missing value in `'Model'`, try using `inplace`!*\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> `# Shape of the dataframe with the missing value 'Model' row gone`\n",
    "\n",
    "> (92, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the row with a missing value in `Model`\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n",
    "# check the shape of the dataframe; there should be 92 rows\n",
    "cars_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the missing value from `Model` was removed\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.10** We can drop entire rows as well. Again, in real life we'd want to investigate before doing this. But this is just for practice! So let's try it out.\n",
    "\n",
    "If you ran the Q.8 code cell correctly, you should see that the column `'Luggage.room'` has 19 missing values. That's way more than any other column of the dataset!\n",
    "\n",
    "Get rid of this column now.\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> `# Shape of the dataframe with \"Luggage.room\" gone`\n",
    "\n",
    "> (92, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.11** Instead of dropping null values, what if we wanted to replace them instead? Called *imputation*, this can be a useful solution if we don't want to drop null observations, or if doing so would reduce our dataset by a significant size.\n",
    "\n",
    "Let's practice simple mean imputation next. Replace the missing values in the `Min.Price` and `Max.Price` columns with their respective means.\n",
    "\n",
    "*Hint: What output did `.describe()` return to you?*\n",
    "\n",
    "*Output:*\n",
    "\n",
    "> `> cars_df['Min.Price'].isna().any()`\n",
    "\n",
    "> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that there are null values; should return `True`\n",
    "\n",
    "cars_df[['Min.Price', 'Max.Price']].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all null values have been removed; should return `False`\n",
    "\n",
    "cars_df[['Min.Price', 'Max.Price']].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.12** Another transformation we might want to perform is **standardization.** This means that all values are **normalized** to have a mean of 0 and a standard deviation of 1, and **scaled** to be in the inclusive range of 0 to 1.\n",
    "\n",
    "Don't worry too much about why we need to do this yet! It will help us build better predictive models in the future.\n",
    "\n",
    "For now, try to standardize the values of any numeric column in the Cars93 dataframe. The numeric columns have been pulled out for you and saved as `numeric_cars_df`.\n",
    "\n",
    "1. **First, fill any missing values with the column mean.**\n",
    "2. **Then, normalize all columns in the dataframe.**\n",
    "3. **Finally, scale all values to be between 0 and 1.**\n",
    "\n",
    "*Hint: You can normalize data by subtracting the mean and dividing by the standard deviation.*\n",
    "\n",
    "*You can scale the data by subtracting it from the max, and dividing by the range `max - min`.*\n",
    "\n",
    "*Sample Output:*\n",
    "\n",
    "> `# First few columns of the first few rows`\n",
    "\n",
    ">           Min.Price   Price      Max.Price\n",
    ">     0     0.84        0.84       0.85       ...\n",
    ">     1     0.42        0.51       0.57       ...\n",
    ">     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out only numeric columns of the dataframe and check that they are not standardized\n",
    "numeric_cars_df = cars_df[list(cars_df.mean().keys())]\n",
    "\n",
    "numeric_cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in all missing values with the column mean\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data (subtract the mean and divide by the standard deviation)\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data between 0 and 1 (subtract it from the max, and divide by the range)\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n",
    "# check that the data is now standardized\n",
    "numeric_cars_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q.13** One last thing we'll look at is text in dataframes. Frequently, our data will be unstructured, and we'll have to do a bit of cleaning up before we could use it.\n",
    "\n",
    "We've already seen how to transform numeric data (by scaling, normalizing, and imputing or dropping missing values). Now, let's take a quick look at how to deal with textual data.\n",
    "\n",
    "If your data comes in one long string, you might want to split it up across different columns and work with each piece separately. For this exercise, we'll take a column full of strings and split it up into three columns.\n",
    "\n",
    "*Output:*\n",
    "\n",
    ">           No.     Name         Kanji\n",
    ">     0     01      Chiyoda      千代田区\n",
    ">     1     03      Minato       港区\n",
    ">     2     04      Shinjuku     新宿区\n",
    ">     3     09      Shinagawa    品川区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and view the dataframe\n",
    "string_dataframe = pd.DataFrame([\"No., Name    Kanji\",\n",
    "\"01, Chiyoda    千代田区\",\n",
    "\"03, Minato    港区\",\n",
    "\"04, Shinjuku    新宿区\",\n",
    "\"09, Shinagawa    品川区\"], columns=['row'])\n",
    "\n",
    "string_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text in each row into 3 new columns\n",
    "\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if necessary, rename the columns and reset the index\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n",
    "# view the final dataframe\n",
    "\n",
    "string_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Matplotlib\n",
    "\n",
    "[intro to what matplotlib is, and why we use it]\n",
    "\n",
    "[what they'll be doing in this section]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- draw simple plot\n",
    "- create multiple subplots\n",
    "- piechart\n",
    "- histogram\n",
    "- bar plot\n",
    "- saving a plot\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/04.00-introduction-to-matplotlib.html\n",
    "\n",
    "https://heartbeat.fritz.ai/introduction-to-matplotlib-data-visualization-in-python-d9143287ae39\n",
    "\n",
    "https://www.tutorialdocs.com/article/python-matplotlib-tutorial.html\n",
    "\n",
    "EXERCISES: https://www.w3resource.com/graphics/matplotlib/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
